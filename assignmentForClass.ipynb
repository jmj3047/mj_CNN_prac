{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 개요\n",
    "- 강의명 : 2022년 K-디지털 직업훈련(Training) 사업 - AI데이터플랫폼을 활용한 빅데이터 분석전문가 과정\n",
    "- 교과목명 : 빅데이터 분석 및 시각화, AI개발 기초, 인공지능 프로그래밍\n",
    "- 프로젝트 주제 : FashionMNIST Data를 사용한 CNN모델 구축\n",
    "- 프로젝트 마감일 : 2022년 4월 12일 화요일\n",
    "- 강사명 : 정지훈 강사\n",
    "- 수강생명 : 장민지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jmj3047/mj_CNN_tutorial\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "drive_project_root = \"/home/jmj3047/mj_CNN_tutorial\"\n",
    "sys.path.append(drive_project_root) #경로 맞춰주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r \"requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch_optimizer import RAdam\n",
    "from torch_optimizer import AdamP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data_root = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "#preprocessing & 데이터 셋 정의\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5],[0.5]), #mean, std\n",
    "    ]\n",
    ")\n",
    "fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist_dataset[0] #리스트 형태로 나옴\n",
    "fashion_mnist_dataset[0][1] #레이블 번호가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split을 써야 함\n",
    "#random_split을 사용해서 데이터를 나눌수 있음\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_split(\n",
    "    fashion_mnist_dataset,\n",
    "    [int(len(fashion_mnist_dataset)*0.7), len(fashion_mnist_dataset)-int(len(fashion_mnist_dataset)*0.7)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위에서는 랜덤으로 split되는 거기 때문에 일정사이즈에 맞춰서 예측할수 있게끔 코드 짜주심\n",
    "from data_utils import dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader 정의\n",
    "\n",
    "datasets = dataset_split(fashion_mnist_dataset,split=[0.9,0.1])\n",
    "#이렇게 하면 train과 val 세트가 나눠짐\n",
    "\n",
    "train_dataset = datasets[\"train\"]\n",
    "val_dataset = datasets[\"val\"]\n",
    "\n",
    "#미니배치: 한번에 얼마나 적용/업데이트 할 것인지 \n",
    "train_batch_size = 100\n",
    "val_batch_size = 10\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size = train_batch_size, shuffle = True, num_workers = 1\n",
    "    #num_workers: 병렬 프로세싱 할 때 얼마나 있는게 좋은지, gpu연산 시 활용\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size = val_batch_size, shuffle = True, num_workers = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]]]), tensor([6, 6, 4, 9, 3, 3, 7, 5, 4, 8, 9, 6, 2, 9, 4, 1, 6, 8, 2, 6, 9, 5, 5, 6,\n",
      "        5, 4, 7, 3, 1, 9, 7, 9, 7, 6, 4, 2, 7, 5, 7, 2, 5, 3, 4, 1, 8, 0, 8, 3,\n",
      "        0, 4, 0, 9, 7, 6, 8, 7, 3, 4, 9, 1, 1, 6, 8, 5, 2, 7, 8, 0, 8, 6, 8, 2,\n",
      "        4, 8, 3, 0, 5, 9, 3, 5, 8, 8, 0, 8, 5, 6, 6, 0, 5, 3, 8, 4, 2, 1, 8, 6,\n",
      "        9, 6, 1, 6])]\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "#샘플 배치가 어떻게 생겼는지\n",
    "for sample_batch in train_dataloader:\n",
    "    print(sample_batch)\n",
    "    print(sample_batch[0].shape, sample_batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 정의\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Define Model.\n",
    "\n",
    "class MLP(nn.Module): #이거 안하면 cpu, gpu에서 꼬임\n",
    "    def __init__(self, in_dim:int, h1_dim: int, h2_dim:int, out_dim:int):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_dim, h1_dim)\n",
    "        self.linear2 = nn.Linear(h1_dim, h2_dim)\n",
    "        self.linear3 = nn.Linear(h2_dim, out_dim)\n",
    "        self.relu = F.relu #활성화 함수 정의\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1) \n",
    "        #데이터 사이즈가 100,1,28,28인데 함수의 인풋은 다차원을 받아들일 준비가 안돼있음. 따라서 flatten을 해주면 100만 빼고 나머지가 flatten됨\n",
    "        x = self.relu(self.linear1(x)) #첫번째 은닉층\n",
    "        x = self.relu(self.linear2(x)) #두번째 은닉층\n",
    "        out = self.linear3(x)\n",
    "        #여기다 시그모이드,소프트 맥스 정의 가능\n",
    "        # out = F.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "#MLP + basic regularizers(Dropout, early stoppig)\n",
    "class MLPWithDropout(MLP):\n",
    "    def __init__(self, in_dim:int, h1_dim: int, h2_dim:int, out_dim:int, dropout_prob:float):\n",
    "        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1) \n",
    "        x = self.relu(self.linear1(x)) #첫번째 은닉층\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.linear2(x)) #두번째 은닉층\n",
    "        x = self.dropout2(x)\n",
    "        out = self.linear3(x)\n",
    "        # out = F.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_1:\n",
      "  conv2d_in_channels: 1\n",
      "  conv2d_out_channels: 32\n",
      "  conv2d_kernel_size: 3\n",
      "  conv2d_padding: 1\n",
      "  maxpool2d_kernel_size: 2\n",
      "  maxpool2d_stride: 2\n",
      "layer_2:\n",
      "  conv2d_in_channels: 32\n",
      "  conv2d_out_channels: 64\n",
      "  conv2d_kernel_size: 3\n",
      "  conv2d_padding: 0\n",
      "  maxpool2d_kernel_size: 2\n",
      "  maxpool2d_stride: 1\n",
      "fc_1:\n",
      "  in_features: 2304\n",
      "  out_features: 512\n",
      "fc_2:\n",
      "  in_features: 512\n",
      "  out_features: 128\n",
      "fc_3:\n",
      "  in_features: 128\n",
      "  out_features: 10\n",
      "dropout_prob: 0.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CNN 모델 정의\n",
    "_cnn_cfg_dict: dict = {\n",
    "    \"layer_1\": {\n",
    "        \"conv2d_in_channels\": 1,\n",
    "        \"conv2d_out_channels\": 32,\n",
    "        \"conv2d_kernel_size\": 3,\n",
    "        \"conv2d_padding\": 1,\n",
    "        \"maxpool2d_kernel_size\": 2,\n",
    "        \"maxpool2d_stride\": 2,\n",
    "    },\n",
    "    \"layer_2\": {\n",
    "        \"conv2d_in_channels\": 32,\n",
    "        \"conv2d_out_channels\": 64,\n",
    "        \"conv2d_kernel_size\": 3,\n",
    "        \"conv2d_padding\": 0,\n",
    "        \"maxpool2d_kernel_size\": 2,\n",
    "        \"maxpool2d_stride\": 1,\n",
    "    },\n",
    "    \"fc_1\": {\n",
    "        \"in_features\": 2304, #  수정 필요!\n",
    "        \"out_features\": 512,\n",
    "    },\n",
    "    \"fc_2\": {\n",
    "        \"in_features\": 512,\n",
    "        \"out_features\": 128,        \n",
    "    },\n",
    "    \"fc_3\": {\n",
    "        \"in_features\": 128,\n",
    "        \"out_features\": 10,\n",
    "    },\n",
    "    \"dropout_prob\": 0.25,\n",
    "}\n",
    "_cnn_cfg = OmegaConf.create(_cnn_cfg_dict)\n",
    "print(OmegaConf.to_yaml(_cnn_cfg))\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, cfg: DictConfig = _cnn_cfg):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=cfg.layer_1.conv2d_in_channels,\n",
    "                out_channels=cfg.layer_1.conv2d_out_channels,\n",
    "                kernel_size=cfg.layer_1.conv2d_kernel_size,\n",
    "                padding=cfg.layer_1.conv2d_padding\n",
    "            ),\n",
    "            nn.BatchNorm2d(cfg.layer_1.conv2d_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=cfg.layer_1.maxpool2d_kernel_size,\n",
    "                stride=cfg.layer_1.maxpool2d_stride\n",
    "            )\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=cfg.layer_2.conv2d_in_channels,\n",
    "                out_channels=cfg.layer_2.conv2d_out_channels,\n",
    "                kernel_size=cfg.layer_2.conv2d_kernel_size,\n",
    "                padding=cfg.layer_2.conv2d_padding\n",
    "            ),\n",
    "            nn.BatchNorm2d(cfg.layer_2.conv2d_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=cfg.layer_2.maxpool2d_kernel_size,\n",
    "                stride=cfg.layer_2.maxpool2d_stride\n",
    "            )\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=cfg.fc_1.in_features,\n",
    "            out_features=cfg.fc_1.out_features,\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=cfg.fc_2.in_features,\n",
    "            out_features=cfg.fc_2.out_features,\n",
    "        )\n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features=cfg.fc_3.in_features,\n",
    "            out_features=cfg.fc_3.out_features,\n",
    "        )\n",
    "        self.dropout = nn.Dropout2d(cfg.dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "# Warmup Scheduler\n",
    "class WarmupLR(optim.lr_scheduler.LambdaLR):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: optim.Optimizer,\n",
    "        warmup_end_steps: int,\n",
    "        last_epoch: int = -1,\n",
    "    ):\n",
    "        \n",
    "        def wramup_fn(step: int):\n",
    "            if step < warmup_end_steps:\n",
    "                return float(step) / float(max(warmup_end_steps, 1))\n",
    "            return 1.0\n",
    "        \n",
    "        super().__init__(optimizer, wramup_fn, last_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPWithDropout\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3chxpza2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1242a7baa4fd4136862dac57e75c3085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">2022-04-06T15:25:55-MLPWithDropout-Adam_optim_0.001_lr_with_WarmupLR_scheduler</strong>: <a href=\"https://wandb.ai/minjeejang/fastcampus_fashion_mnist_tutorials/runs/3chxpza2\" target=\"_blank\">https://wandb.ai/minjeejang/fastcampus_fashion_mnist_tutorials/runs/3chxpza2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220406_152555-3chxpza2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3chxpza2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jmj3047/mj_CNN_tutorial/wandb/run-20220406_152913-2tjkzvr7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/minjeejang/fastcampus_fashion_mnist_tutorials/runs/2tjkzvr7\" target=\"_blank\">2022-04-06T15:29:13-MLPWithDropout-Adam_optim_0.001_lr_with_WarmupLR_scheduler</a></strong> to <a href=\"https://wandb.ai/minjeejang/fastcampus_fashion_mnist_tutorials\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#모델 선언 및 손실함수 정의, optimizer 정의, logger(tensorboard) 정의\n",
    "\n",
    "# # gpu setup\n",
    "gpu = None\n",
    "#gpu = 0\n",
    "# gpu = os.environ[\"CUDA_VISIBLE_DEVICES\"]=3\n",
    "\n",
    "#define model\n",
    "#model = MLP(28*28, 128, 64, 10)\n",
    "model = MLPWithDropout(28*28, 128, 64, 10, dropout_prob=0.3)\n",
    "model_name = type(model).__name__ #모델을 먼저 선언해주면 어떤모델로 사용하는지 보여줌\n",
    "print(model_name)\n",
    "\n",
    "#data loss\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#define optimizer\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = RAdam(model.parameters(), lr=lr)\n",
    "# optimizer = AdamP(model.parameters(), lr=lr)\n",
    "optimizer_name = type(optimizer).__name__\n",
    "\n",
    "# define scheduler\n",
    "scheduler = WarmupLR(optimizer, 1500)\n",
    "scheduler_name = type(scheduler).__name__ if scheduler is not None else \"no\"\n",
    "\n",
    "max_epoch = 10\n",
    "\n",
    "#define tensorboard logger\n",
    "run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{model_name}-{optimizer_name}_optim_{lr}_lr_with_{scheduler_name}_scheduler\"\n",
    "run_dirname = \"dnn-tutorial-fashion-mnist-runs\"\n",
    "log_dir = os.path.join(drive_project_root, \"runs\", run_dirname, run_name)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "#log interval\n",
    "log_interval = 100 #100번마다 찍음\n",
    "\n",
    "# define wandb\n",
    "project_name = \"fastcampus_fashion_mnist_tutorials\"\n",
    "run_tags = [project_name]\n",
    "wandb.init(\n",
    "    project=project_name,\n",
    "    name=run_name,\n",
    "    tags=run_tags,\n",
    "    config={\"lr\": lr, \"model_name\": model_name, \"optimizer_name\": optimizer_name, \"scheduler_name\": scheduler_name},\n",
    "    reinit=True,\n",
    ")\n",
    "\n",
    "# set save model path\n",
    "log_model_path = os.path.join(log_dir, \"models\")\n",
    "os.makedirs(log_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early Stopping callback Object Class 정의\n",
    "\n",
    "# With some modifications, source is from https://github.com/Bjarten/early-stopping-pytorch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.ckpt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.ckpt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        \n",
    "        filename = self.path.split('/')[-1]\n",
    "        save_dir = os.path.dirname(self.path)\n",
    "        torch.save(model, os.path.join(save_dir, f\"val_loss-{val_loss}-{filename}\"))\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17880), started 2 days, 3:44:45 ago. (Use '!kill 17880' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-af9f47ebf30614d9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-af9f47ebf30614d9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 600/600 [00:05<00:00, 107.09it/s]\n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch, 0 step: val_loss: 0.22985124588012695, val_acc: 0.09283319860696793\n",
      "Validation loss decreased (inf --> 0.229851).  Saving model ...\n",
      "0: train_loss: 0.022927565574645994, train_acc: 0.07000000029802322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  19%|█▉        | 104/540 [00:09<00:21, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: train_loss: 0.02007065773010254, train_acc: 0.36000001430511475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  37%|███▋      | 200/540 [00:14<00:08, 39.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: train_loss: 0.011864114999771119, train_acc: 0.5799999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  56%|█████▌    | 303/540 [00:22<00:16, 14.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300: train_loss: 0.008239740133285522, train_acc: 0.6899999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  74%|███████▍  | 402/540 [00:27<00:04, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: train_loss: 0.008309401869773865, train_acc: 0.7699999809265137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  93%|█████████▎| 503/540 [00:36<00:03, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: train_loss: 0.0064211893081665035, train_acc: 0.7699999809265137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:38<00:00, 14.13it/s]\n",
      "validation: 100%|██████████| 600/600 [00:07<00:00, 84.40it/s] \n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch, 540 step: val_loss: 0.05393615737557411, val_acc: 0.8004986643791199\n",
      "Validation loss decreased (0.229851 --> 0.053936).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  11%|█▏        | 62/540 [00:04<01:07,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600: train_loss: 0.006997644305229187, train_acc: 0.7900000214576721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  31%|███       | 165/540 [00:10<00:12, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700: train_loss: 0.004065274298191071, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  48%|████▊     | 261/540 [00:18<00:21, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800: train_loss: 0.006907865405082703, train_acc: 0.8199999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  66%|██████▋   | 359/540 [00:23<00:05, 35.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900: train_loss: 0.005617197155952453, train_acc: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  86%|████████▌ | 462/540 [00:31<00:06, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: train_loss: 0.004827341735363006, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:36<00:00, 14.75it/s]\n",
      "validation: 100%|██████████| 600/600 [00:05<00:00, 110.51it/s]\n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch, 1080 step: val_loss: 0.043894585222005844, val_acc: 0.8348316550254822\n",
      "Validation loss decreased (0.053936 --> 0.043895).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   4%|▍         | 21/540 [00:03<00:45, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100: train_loss: 0.005633728504180908, train_acc: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  23%|██▎       | 122/540 [00:08<00:14, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200: train_loss: 0.005617084503173828, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  41%|████▏     | 223/540 [00:16<00:33,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300: train_loss: 0.005447611212730408, train_acc: 0.8100000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  60%|██████    | 324/540 [00:22<00:07, 28.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400: train_loss: 0.004691483974456787, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  78%|███████▊  | 422/540 [00:30<00:12,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500: train_loss: 0.004939497411251068, train_acc: 0.8100000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  96%|█████████▌| 518/540 [00:35<00:00, 35.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600: train_loss: 0.006664305925369263, train_acc: 0.7599999904632568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:38<00:00, 13.88it/s]\n",
      "validation: 100%|██████████| 600/600 [00:05<00:00, 110.94it/s]\n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch, 1620 step: val_loss: 0.04015584662556648, val_acc: 0.853498101234436\n",
      "Validation loss decreased (0.043895 --> 0.040156).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  14%|█▍        | 78/540 [00:05<00:35, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700: train_loss: 0.002808903157711029, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  34%|███▍      | 183/540 [00:13<00:21, 16.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800: train_loss: 0.0034350281953811645, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  53%|█████▎    | 284/540 [00:18<00:08, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900: train_loss: 0.003984178304672241, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  71%|███████   | 381/540 [00:26<00:17,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000: train_loss: 0.00531227707862854, train_acc: 0.8100000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  90%|████████▉ | 485/540 [00:32<00:01, 28.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100: train_loss: 0.0041820770502090454, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:36<00:00, 14.81it/s]\n",
      "validation: 100%|██████████| 600/600 [00:06<00:00, 98.65it/s] \n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch, 2160 step: val_loss: 0.038012098520994186, val_acc: 0.8614979982376099\n",
      "Validation loss decreased (0.040156 --> 0.038012).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   8%|▊         | 43/540 [00:03<00:17, 28.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200: train_loss: 0.005906157493591309, train_acc: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  26%|██▌       | 141/540 [00:11<00:50,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300: train_loss: 0.0044090116024017335, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  45%|████▌     | 244/540 [00:17<00:21, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400: train_loss: 0.0057644879817962645, train_acc: 0.8100000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  63%|██████▎   | 341/540 [00:22<00:11, 17.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500: train_loss: 0.0055582720041275025, train_acc: 0.8100000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  81%|████████▏ | 439/540 [00:27<00:02, 38.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600: train_loss: 0.0029764649271965026, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:32<00:00, 16.49it/s]\n",
      "validation: 100%|██████████| 600/600 [00:08<00:00, 73.58it/s] \n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 epoch, 2700 step: val_loss: 0.037079211324453354, val_acc: 0.8668314814567566\n",
      "Validation loss decreased (0.038012 --> 0.037079).  Saving model ...\n",
      "2700: train_loss: 0.002936837375164032, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  18%|█▊        | 98/540 [00:05<00:11, 37.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800: train_loss: 0.004697108566761017, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  37%|███▋      | 202/540 [00:14<00:22, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900: train_loss: 0.003927461206912995, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  56%|█████▌    | 301/540 [00:19<00:08, 27.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000: train_loss: 0.005618944764137268, train_acc: 0.8199999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  75%|███████▍  | 403/540 [00:27<00:06, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100: train_loss: 0.003249891996383667, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  92%|█████████▏| 498/540 [00:32<00:01, 31.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: train_loss: 0.005001215934753418, train_acc: 0.7900000214576721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:36<00:00, 14.86it/s]\n",
      "validation: 100%|██████████| 600/600 [00:05<00:00, 109.18it/s]\n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 epoch, 3240 step: val_loss: 0.03604898974299431, val_acc: 0.872164785861969\n",
      "Validation loss decreased (0.037079 --> 0.036049).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  10%|█         | 56/540 [00:03<00:12, 39.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300: train_loss: 0.00423274964094162, train_acc: 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  30%|██▉       | 161/540 [00:11<00:36, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400: train_loss: 0.0031965887546539307, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  49%|████▊     | 262/540 [00:17<00:10, 26.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500: train_loss: 0.002007903903722763, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  67%|██████▋   | 361/540 [00:25<00:14, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600: train_loss: 0.004444378912448883, train_acc: 0.8199999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  85%|████████▌ | 460/540 [00:30<00:02, 34.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700: train_loss: 0.0032509589195251465, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:37<00:00, 14.30it/s]\n",
      "validation: 100%|██████████| 600/600 [00:05<00:00, 100.74it/s]\n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 epoch, 3780 step: val_loss: 0.03481597080826759, val_acc: 0.8733314871788025\n",
      "Validation loss decreased (0.036049 --> 0.034816).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   4%|▍         | 21/540 [00:00<00:19, 26.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800: train_loss: 0.0023615217208862306, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  23%|██▎       | 123/540 [00:08<00:33, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900: train_loss: 0.0034804856777191162, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  41%|████▏     | 224/540 [00:14<00:10, 29.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000: train_loss: 0.004171576797962189, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  59%|█████▉    | 321/540 [00:22<00:17, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100: train_loss: 0.002495213747024536, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  78%|███████▊  | 422/540 [00:27<00:03, 29.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200: train_loss: 0.0020317941904067992, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  96%|█████████▋| 521/540 [00:35<00:01, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300: train_loss: 0.0021232807636260985, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:36<00:00, 14.86it/s]\n",
      "validation: 100%|██████████| 600/600 [00:08<00:00, 72.47it/s] \n",
      "Train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 epoch, 4320 step: val_loss: 0.03460345044732094, val_acc: 0.8731644749641418\n",
      "Validation loss decreased (0.034816 --> 0.034603).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  16%|█▌        | 84/540 [00:05<00:24, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400: train_loss: 0.003855233788490295, train_acc: 0.8100000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  33%|███▎      | 178/540 [00:10<00:09, 37.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500: train_loss: 0.0032953548431396483, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  53%|█████▎    | 284/540 [00:18<00:14, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600: train_loss: 0.0017591959238052368, train_acc: 0.9599999785423279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  71%|███████   | 384/540 [00:23<00:04, 33.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700: train_loss: 0.0033897238969802855, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  89%|████████▉ | 480/540 [00:28<00:01, 39.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800: train_loss: 0.0024532918632030488, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 540/540 [00:33<00:00, 16.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#logging 하는 방법\n",
    "%load_ext tensorboard \n",
    "#외부에서 텐서보드를 가지고 온다\n",
    "%tensorboard --logdir runs/ \n",
    "#runs라는 폴더를 만들고 거기다가 logging을 쌓고 그걸 plot하는 것\n",
    "\n",
    "# define EarlyStopping.\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=3, verbose=True, path=os.path.join(log_model_path, \"model.ckpt\")\n",
    ")\n",
    "\n",
    "# do train with validation.\n",
    "train_step = 0\n",
    "for epoch in range(1, max_epoch):\n",
    "    \n",
    "    #Validation step: optimization는 업데이트 안함\n",
    "    with torch.no_grad():\n",
    "        val_loss =0.0\n",
    "        val_corrects = 0\n",
    "        model.eval()\n",
    "\n",
    "        for val_batch_idx, (val_images, val_labels) in enumerate(\n",
    "            tqdm(val_dataloader, position =0, leave= True, desc='validation') #tqdm은 예쁘게 정리해줌\n",
    "        ):\n",
    "\n",
    "            if gpu is not None:\n",
    "                val_images = val_images.cuda(gpu, non_blocking=True)\n",
    "                val_labels = val_labels.cuda(gpu, non_blocking=True)\n",
    "\n",
    "            #forward까지는 똑같음\n",
    "            val_outputs = model(val_images)\n",
    "            _,val_preds = torch.max(val_outputs,1)\n",
    "\n",
    "            #loss & acc\n",
    "            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n",
    "            #val_lables/ val_outputs.shape[0]: 배치 사이즈, 이걸로 평균 내겠다. \n",
    "            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n",
    "        \n",
    "    #validation step logging\n",
    "    val_epoch_loss = val_loss / len(val_dataloader)\n",
    "    val_epoch_acc = val_corrects / len(val_dataloader)\n",
    "\n",
    "    print(\n",
    "        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n",
    "    )\n",
    "\n",
    "    #tensorboard write\n",
    "    writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n",
    "    writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n",
    "    writer.add_images(\"Images/val\", val_images, train_step)\n",
    "\n",
    "    # wandb log\n",
    "    wandb.log({\n",
    "        \"Loss/val\": val_epoch_loss,\n",
    "        \"Acc/val\": val_epoch_acc,\n",
    "        \"Images/val\": wandb.Image(val_images),\n",
    "        \"Outputs/val\": wandb.Histogram(val_outputs.detach().cpu().numpy()),\n",
    "        \"Preds/val\": wandb.Histogram(val_preds.detach().cpu().numpy()),\n",
    "        \"Labels/val\": wandb.Histogram(val_labels.data.detach().cpu().numpy()),\n",
    "    }, step=train_step)\n",
    "\n",
    "    # check model early stopping point & save model if the model reached the best performance.\n",
    "    early_stopper(val_epoch_loss, model)\n",
    "    if early_stopper.early_stop:\n",
    "        break\n",
    "    \n",
    "    #로깅이 끝났기 때문에 로스를 초기화 해서 처음부터 다시 더해질수 있게 함\n",
    "    current_loss = 0 \n",
    "    current_corrects = 0\n",
    "\n",
    "    #Train step\n",
    "    model.train()\n",
    "    #학습 데이터에 대해서 가지고 오고 훈련 진행\n",
    "    for batch_idx, (images, labels) in enumerate( #batch 인덱스랑 라벨을 계속 확인 함\n",
    "        tqdm(train_dataloader, position =0, leave= True, desc='Train') #어떻게 나오는지 보기위해 data loader를 켜줌\n",
    "    ):\n",
    "        if gpu is not None:\n",
    "            images = images.cuda(gpu)\n",
    "            labels = labels.cuda(gpu)\n",
    "\n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0 #로스와 정확도 체크\n",
    "\n",
    "        # forward\n",
    "        #get prediction, 결과를 얻는 방법\n",
    "        outputs = model(images) #이거만 하면 softmax를 안해서 뒤죽박죽으로 나옴\n",
    "        \n",
    "        #그래서 여기서 max 값의 index를 가지고오는 코드를 짬\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        #get loss (loss 계산)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # backpropagation\n",
    "        #optimization 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Perform LR scheduler Work\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        current_corrects += torch.sum(preds==labels.data)\n",
    "\n",
    "        #logging, 좀 더 정확하게 보기 위해서 평균 값 봄\n",
    "        if train_step % log_interval == 0:\n",
    "            train_loss = current_loss / log_interval\n",
    "            train_acc = current_corrects / log_interval\n",
    "\n",
    "            print(\n",
    "                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n",
    "            )\n",
    "            \n",
    "            cur_lr = optimizer.param_groups[0][\"lr\"] if scheduler is None else scheduler.get_last_lr()[0]   \n",
    "\n",
    "            #tensorboard write\n",
    "            writer.add_scalar(\"Loss/train\", train_loss, train_step)\n",
    "            writer.add_scalar(\"Acc/train\", train_acc, train_step)\n",
    "            writer.add_images(\"Images/train\", images, train_step)\n",
    "            writer.add_graph(model, images)\n",
    "\n",
    "            # wandb log\n",
    "            wandb.log({\n",
    "                \"Loss/train\": train_loss,\n",
    "                \"Acc/train\": train_acc,\n",
    "                \"Images/train\": wandb.Image(images),\n",
    "                \"Outputs/train\": wandb.Histogram(outputs.detach().cpu().numpy()),\n",
    "                \"Preds/train\": wandb.Histogram(preds.detach().cpu().numpy()),\n",
    "                \"Labels/train\": wandb.Histogram(labels.data.detach().cpu().numpy()),\n",
    "                \"Learning Rate\": cur_lr,\n",
    "            }, step=train_step)\n",
    "            \n",
    "            #로깅이 끝났기 때문에 로스를 초기화 해서 처음부터 다시 더해질수 있게 함\n",
    "            current_loss = 0 \n",
    "            current_corrects = 0\n",
    "\n",
    "        train_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 저장\n",
    "#torch.save(model, os.path.join(log_model_path, \"mlp.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPWithDropout(\n",
      "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.043894585222005844-model.ckpt\"))\n",
    "loaded_model.eval() #test모드일때 사용. 굉장히 중요\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax function definition\n",
    "def softmax(x, axis=0):\n",
    "    \"numpy softmax\"\n",
    "    max = np.max(x, axis=axis, keepdims=True)\n",
    "    e_x = np.exp(x - max)\n",
    "    sum = np.sum(e_x, axis=axis, keepdims=True)\n",
    "    f_x = e_x / sum\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 100/100 [00:01<00:00, 69.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 71.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 100\n",
    "test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n",
    "teset_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "test_labels_list = []\n",
    "test_preds_list = []\n",
    "test_outputs_list = []\n",
    "\n",
    "for i, (test_images, test_labels) in enumerate(tqdm(teset_dataloader, position=0, leave=True, desc=\"test\")):\n",
    "    #forward\n",
    "    test_outputs = loaded_model(test_images)\n",
    "    _, test_preds = torch.max(test_outputs, 1)\n",
    "\n",
    "    #output에 대해서 softmax를 채워줌\n",
    "    final_outs = softmax(test_outputs.detach().numpy(), axis=1) #detach는 gpu에 있던걸 cpu로 넘겨주는 것\n",
    "    test_outputs_list.extend(final_outs)\n",
    "    test_preds_list.extend(test_preds.detach().numpy())\n",
    "    test_labels_list.extend(test_labels.detach().numpy())\n",
    "\n",
    "test_preds_list = np.array(test_preds_list)\n",
    "test_labels_list = np.array(test_labels_list)\n",
    "\n",
    "print(f\"acc: {np.mean(test_preds_list == test_labels_list)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score 0.9738060777777778\n"
     ]
    }
   ],
   "source": [
    "# ROC Curve:이것이 얼마나 decision boundary를 서서히 움직여 가면서 성능이 나오는지 확인\n",
    "#acc만으로 성능이 잘 안나오는 경우가 있기 때문에 확인\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh = {}\n",
    "n_class = 10\n",
    "\n",
    "for i in range(n_class):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n",
    "\n",
    "# plot.\n",
    "for i in range(n_class):\n",
    "    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n",
    "plt.title(\"Multi-class ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(\"auc_score\", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7244abc13d988a7e7d2c4c53272249ae82a63923609912adda01122398923101"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
